{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for match final results predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "\n",
    "#pd.set_option('display.max_rows', )\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = 'PS'\n",
    "H = bm + 'H'\n",
    "D = bm + 'D'\n",
    "A = bm + 'A'\n",
    "\n",
    "k = 49.5\n",
    "\n",
    "def get_best(s):\n",
    "\n",
    "    h = s.FTHG\n",
    "    a = s.FTAG\n",
    "\n",
    "    BH = s[H + '_P']\n",
    "    BD = s[D + '_P']\n",
    "    BA = s[A + '_P']\n",
    "\n",
    "\n",
    "    if BH == max(BH, BD, BA, k) and h > a or \\\n",
    "       BD == max(BH, BD, BA, k) and h == a or \\\n",
    "       BA == max(BH, BD, BA, k) and h < a :\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_1 = \"Serie-A-2122.csv\"\n",
    "filename_2 = \"Serie-A-2223.csv\"\n",
    "filename_3 = \"Premier-league-2122.csv\"\n",
    "filename_4 = \"Premier-league-2223.csv\"\n",
    "filename_5 = \"Bundesliga-2122.csv\"\n",
    "filename_6 = \"Bundesliga-2223.csv\"\n",
    "filename_7 = \"Liga-2122.csv\"\n",
    "filename_8 = \"Liga-2223.csv\"\n",
    "filename_9  = \"Ligue1-2122.csv\"\n",
    "filename_10 = \"Ligue1-2223.csv\"\n",
    "filename_11 = \"Super-lig-2122.csv\"\n",
    "filename_12 = \"Super-lig-2223.csv\"\n",
    "filename_13 = \"Eredivise-2122.csv\"\n",
    "filename_14 = \"Eredivise-2223.csv\"\n",
    "filename_15 = \"Liga-1-2122.csv\"\n",
    "filename_16 = \"Liga-1-2223.csv\"\n",
    "filename_17 = \"Serie-A-2021.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5623, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the datasets\n",
    "\n",
    "filenames = [filename_1, filename_2, filename_3, filename_4,\n",
    "             filename_5, filename_6, filename_7, filename_8,\n",
    "             filename_9, filename_10, filename_11, filename_12,\n",
    "             filename_13, filename_14, filename_15, filename_16,\n",
    "             filename_17]\n",
    "\n",
    "tmp_features = ['HomeTeam','AwayTeam','FTHG','FTAG', H, D, A]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name in filenames:\n",
    "    tmp = pd.read_csv(name, sep=',')\n",
    "    df = pd.concat([df, tmp[tmp_features]])\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the result_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PS_income_index\n",
       "0    3741\n",
       "1    1882\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[H + '_P'] = round(100/(1 + df[H]*(1/df[D] + 1/df[A])), 2)\n",
    "df[A + '_P'] = round(100/(1 + df[A]*(1/df[H] + 1/df[D])), 2)\n",
    "df[D + '_P'] = round(100/(1 + df[D]*(1/df[H] + 1/df[A])), 2)\n",
    "\n",
    "features = [H, D, A]\n",
    "target   = [bm + '_income_index']\n",
    "\n",
    "df[bm + '_income_index'] = df.apply(get_best, axis=1)\n",
    "df[bm + '_income_index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5400212539851221"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[bm + '_income_index'] == 1][[bm + 'H', bm + 'D', bm + 'A']].apply(lambda x: min(x[bm + 'H'], x[bm + 'D'], x[bm + 'A']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87      1528\n",
      "           1       0.70      0.81      0.75       713\n",
      "\n",
      "    accuracy                           0.83      2241\n",
      "   macro avg       0.80      0.82      0.81      2241\n",
      "weighted avg       0.84      0.83      0.83      2241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = np.concatenate((df[features].to_numpy(), df[features].to_numpy()))\n",
    "y = np.concatenate((df[target].to_numpy(),   df[target].to_numpy())).squeeze()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val   = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'algorithm': 'auto', 'n_jobs': 8, 'n_neighbors': 34, 'weights': 'distance'}\n",
      "Best cross-validation score: 0.83\n",
      "Test set score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [x for x in range(1, 35)],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'n_jobs': [8]\n",
    "}\n",
    "\n",
    "# definizione del metodo di ricerca migliore combinazione di iper-parametri\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "\n",
    "grid_search.fit(X_val, y_val)\n",
    "\n",
    "# stampa dei migliori parametri e punteggi ottenuti\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7440\n",
      "           1       1.00      1.00      1.00      3764\n",
      "\n",
      "    accuracy                           1.00     11204\n",
      "   macro avg       1.00      1.00      1.00     11204\n",
      "weighted avg       1.00      1.00      1.00     11204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = KNeighborsClassifier(algorithm='auto', n_jobs=-1, n_neighbors=35, weights='distance')\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X)\n",
    "print(classification_report(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pk.dump(clf, open(\"model.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
